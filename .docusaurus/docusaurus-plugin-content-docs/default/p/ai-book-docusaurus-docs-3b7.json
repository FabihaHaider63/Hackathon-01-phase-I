{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Physical AI & Humanoid Robotics Textbook","items":[{"type":"category","label":"Module 1: Weeks 1-2: Introduction to Physical AI","items":[{"type":"link","href":"/ai-book-docusaurus/docs/module-1/intro","label":"Introduction to ROS 2 for Humanoid Robotics","docId":"module-1/intro","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-1/urdf-humanoid","label":"URDF for Humanoid Robot Modeling","docId":"module-1/urdf-humanoid","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-1/python-ros-integration","label":"Bridging Python AI Agents with ROS Controllers","docId":"module-1/python-ros-integration","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-1/sensor-systems","label":"Sensor Systems Overview","docId":"module-1/sensor-systems","unlisted":false}],"collapsed":false,"collapsible":true},{"type":"category","label":"Module 2: Weeks 3-7: ROS 2 Fundamentals & Robot Simulation with Gazebo","items":[{"type":"link","href":"/ai-book-docusaurus/docs/module-2/intro","label":"Introduction to the Digital Twin","docId":"module-2/intro","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-2/urdf-sdf-formats","label":"URDF & SDF Formats","docId":"module-2/urdf-sdf-formats","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-2/ros2-fundamentals","label":"ROS 2 Fundamentals (Weeks 3–5)","docId":"module-2/ros2-fundamentals","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-2/nodes-topics-services-actions","label":"Nodes, Topics, Services, Actions","docId":"module-2/nodes-topics-services-actions","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-2/building-ros2-packages-python","label":"Building ROS 2 Packages (Python)","docId":"module-2/building-ros2-packages-python","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-2/gazebo-environment-setup","label":"Gazebo Environment Setup","docId":"module-2/gazebo-environment-setup","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-2/sensor-simulation","label":"Sensor Simulation (LiDAR, Depth, IMU)","docId":"module-2/sensor-simulation","unlisted":false}],"collapsed":false,"collapsible":true},{"type":"category","label":"Module 3: Weeks 8-10: The AI-Robot Brain (NVIDIA Isaac™)","items":[{"type":"link","href":"/ai-book-docusaurus/docs/module-3/intro","label":"AI-Robot Brain Overview","docId":"module-3/intro","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-3/nvidia-isaac-architecture","label":"NVIDIA Isaac Architecture","docId":"module-3/nvidia-isaac-architecture","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-3/cognitive-planning-actions","label":"Cognitive Planning & Actions","docId":"module-3/cognitive-planning-actions","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-3/isaac-environment-setup","label":"Isaac Environment Setup","docId":"module-3/isaac-environment-setup","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-3/perception-ai-models","label":"Perception & AI Models","docId":"module-3/perception-ai-models","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-3/training-loop","label":"Training Loop","docId":"module-3/training-loop","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-3/sim-to-real-bridge","label":"Sim-to-Real Bridge","docId":"module-3/sim-to-real-bridge","unlisted":false}],"collapsed":false,"collapsible":true},{"type":"category","label":"Module 4: Weeks 11-13: Vision-Language-Action (VLA)","items":[{"type":"link","href":"/ai-book-docusaurus/docs/module-4/vla-overview","label":"VLA Overview","docId":"module-4/vla-overview","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-4/voice-to-action-whisper","label":"Voice-to-Action with OpenAI Whisper","docId":"module-4/voice-to-action-whisper","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-4/cognitive-planning-llm-ros","label":"Cognitive Planning - LLM → ROS 2 Actions","docId":"module-4/cognitive-planning-llm-ros","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-4/humanoid-kinematics-dynamics","label":"Humanoid Kinematics & Dynamics","docId":"module-4/humanoid-kinematics-dynamics","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-4/bipedal-locomotion-balance","label":"Bipedal Locomotion & Balance Control","docId":"module-4/bipedal-locomotion-balance","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-4/manipulation-grasping","label":"Manipulation & Grasping","docId":"module-4/manipulation-grasping","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-4/multi-modal-interaction","label":"Multi-Modal Interaction","docId":"module-4/multi-modal-interaction","unlisted":false},{"type":"link","href":"/ai-book-docusaurus/docs/module-4/capstone-autonomous-humanoid","label":"Capstone - Autonomous Humanoid","docId":"module-4/capstone-autonomous-humanoid","unlisted":false}],"collapsed":false,"collapsible":true}],"collapsed":false,"collapsible":true}]},"docs":{"intro":{"id":"intro","title":"Introduction to the AI-Driven Book on ROS 2","description":"Welcome to the comprehensive guide on Robot Operating System 2 (ROS 2) for humanoid robotics. This book is designed to bridge the gap between digital AI and physical AI, teaching you how to create intelligent, embodied systems."},"module-1/chapter-outline":{"id":"module-1/chapter-outline","title":"Module 1: The Robotic Nervous System (ROS 2) - Chapter Outline","description":"Module Overview"},"module-1/intro":{"id":"module-1/intro","title":"Introduction to ROS 2 for Humanoid Robotics","description":"An introduction to Robot Operating System 2 concepts and how they apply to humanoid robotics","sidebar":"tutorialSidebar"},"module-1/nodes-topics-services":{"id":"module-1/nodes-topics-services","title":"ROS 2 Nodes, Topics, and Services","description":"Understanding the fundamental communication patterns in ROS 2 for humanoid robotics applications"},"module-1/python-ros-integration":{"id":"module-1/python-ros-integration","title":"Bridging Python AI Agents with ROS Controllers","description":"Integrating Python-based AI agents with ROS 2 control systems for humanoid robotics","sidebar":"tutorialSidebar"},"module-1/sensor-systems":{"id":"module-1/sensor-systems","title":"Sensor Systems Overview","description":"Understanding LIDAR, cameras, IMUs, and force/torque sensors for humanoid robotics","sidebar":"tutorialSidebar"},"module-1/urdf-humanoid":{"id":"module-1/urdf-humanoid","title":"URDF for Humanoid Robot Modeling","description":"Understanding and creating Universal Robot Description Format (URDF) models for humanoid robots","sidebar":"tutorialSidebar"},"module-2/building-ros2-packages-python":{"id":"module-2/building-ros2-packages-python","title":"Building ROS 2 Packages (Python)","description":"Creating and structuring ROS 2 packages using Python for humanoid robotics applications","sidebar":"tutorialSidebar"},"module-2/gazebo-environment-setup":{"id":"module-2/gazebo-environment-setup","title":"Gazebo Environment Setup","description":"Setting up Gazebo simulation environments for humanoid robotics applications","sidebar":"tutorialSidebar"},"module-2/gazebo-simulation":{"id":"module-2/gazebo-simulation","title":"Gazebo Simulation (Weeks 6–7)","description":"Setting up and using Gazebo for humanoid robot simulation in the digital twin workflow"},"module-2/high-fidelity-rendering":{"id":"module-2/high-fidelity-rendering","title":"High-Fidelity Rendering","description":"Techniques for achieving photorealistic rendering of humanoid robots and environments in Unity"},"module-2/human-robot-interaction-unity":{"id":"module-2/human-robot-interaction-unity","title":"Human–Robot Interaction in Unity","description":"Creating intuitive interfaces and interaction systems for humans to work with humanoid robots in Unity-based digital twins"},"module-2/intro":{"id":"module-2/intro","title":"Introduction to the Digital Twin","description":"Understanding digital twins in robotics and their role in humanoid robot development","sidebar":"tutorialSidebar"},"module-2/launch-files-parameters":{"id":"module-2/launch-files-parameters","title":"Launch Files & Parameters","description":"Understanding and creating ROS 2 launch files and parameter configurations for humanoid robotics"},"module-2/nodes-topics-services-actions":{"id":"module-2/nodes-topics-services-actions","title":"Nodes, Topics, Services, Actions","description":"Understanding the fundamental communication patterns in ROS 2 for humanoid robotics applications","sidebar":"tutorialSidebar"},"module-2/physics-gravity-collision-simulation":{"id":"module-2/physics-gravity-collision-simulation","title":"Physics, Gravity, Collision Simulation","description":"Understanding physics simulation in Gazebo for humanoid robots including gravity, collision detection, and realistic dynamics"},"module-2/ros2-architecture":{"id":"module-2/ros2-architecture","title":"ROS 2 Architecture","description":"Understanding the architecture and design principles of ROS 2 for humanoid robotics applications"},"module-2/ros2-fundamentals":{"id":"module-2/ros2-fundamentals","title":"ROS 2 Fundamentals (Weeks 3–5)","description":"Core concepts of ROS 2 architecture, nodes, topics, services, and actions for humanoid robotics","sidebar":"tutorialSidebar"},"module-2/sensor-simulation":{"id":"module-2/sensor-simulation","title":"Sensor Simulation (LiDAR, Depth, IMU)","description":"Understanding sensor simulation in Gazebo for humanoid robots, including LiDAR, depth cameras, and IMU sensors","sidebar":"tutorialSidebar"},"module-2/unity-visualization":{"id":"module-2/unity-visualization","title":"Unity Visualization","description":"Creating high-fidelity visualization of humanoid robots in Unity for digital twin applications"},"module-2/urdf-sdf-formats":{"id":"module-2/urdf-sdf-formats","title":"URDF & SDF Formats","description":"Understanding URDF and SDF formats for robot modeling in ROS 2 and Gazebo simulation","sidebar":"tutorialSidebar"},"module-3/cognitive-planning-actions":{"id":"module-3/cognitive-planning-actions","title":"Cognitive Planning & Actions","description":"Understanding cognitive planning and action execution in humanoid robots using NVIDIA Isaac","sidebar":"tutorialSidebar"},"module-3/intro":{"id":"module-3/intro","title":"AI-Robot Brain Overview","description":"Understanding the AI components of humanoid robotics using NVIDIA Isaac","sidebar":"tutorialSidebar"},"module-3/isaac-environment-setup":{"id":"module-3/isaac-environment-setup","title":"Isaac Environment Setup","description":"Setting up the NVIDIA Isaac environment for humanoid robotics development","sidebar":"tutorialSidebar"},"module-3/nvidia-isaac-architecture":{"id":"module-3/nvidia-isaac-architecture","title":"NVIDIA Isaac Architecture","description":"Understanding the components and architecture of the NVIDIA Isaac platform","sidebar":"tutorialSidebar"},"module-3/perception-ai-models":{"id":"module-3/perception-ai-models","title":"Perception & AI Models","description":"Implementing perception systems and AI models for humanoid robots using Isaac ROS","sidebar":"tutorialSidebar"},"module-3/sim-to-real-bridge":{"id":"module-3/sim-to-real-bridge","title":"Sim-to-Real Bridge","description":"Transferring trained models and behaviors from simulation to real humanoid robots","sidebar":"tutorialSidebar"},"module-3/training-loop":{"id":"module-3/training-loop","title":"Training Loop","description":"Implementing reinforcement learning and training loops for humanoid robot control using Isaac","sidebar":"tutorialSidebar"},"module-4/bipedal-locomotion-balance":{"id":"module-4/bipedal-locomotion-balance","title":"Bipedal Locomotion & Balance Control","description":"Understanding the principles of bipedal walking and balance control in humanoid robots","sidebar":"tutorialSidebar"},"module-4/capstone-autonomous-humanoid":{"id":"module-4/capstone-autonomous-humanoid","title":"Capstone - Autonomous Humanoid","description":"Integrating all components into a fully autonomous humanoid robot system","sidebar":"tutorialSidebar"},"module-4/cognitive-planning-llm-ros":{"id":"module-4/cognitive-planning-llm-ros","title":"Cognitive Planning - LLM → ROS 2 Actions","description":"Implementing cognitive planning using Large Language Models to generate ROS 2 actions","sidebar":"tutorialSidebar"},"module-4/humanoid-kinematics-dynamics":{"id":"module-4/humanoid-kinematics-dynamics","title":"Humanoid Kinematics & Dynamics","description":"Understanding the mathematical models governing humanoid robot movement and force interactions","sidebar":"tutorialSidebar"},"module-4/manipulation-grasping":{"id":"module-4/manipulation-grasping","title":"Manipulation & Grasping","description":"Techniques for robotic manipulation and object grasping in humanoid robots","sidebar":"tutorialSidebar"},"module-4/multi-modal-interaction":{"id":"module-4/multi-modal-interaction","title":"Multi-Modal Interaction","description":"Integrating vision, language, and action for natural human-robot interaction","sidebar":"tutorialSidebar"},"module-4/vla-overview":{"id":"module-4/vla-overview","title":"VLA Overview","description":"Understanding Vision-Language-Action systems in humanoid robotics","sidebar":"tutorialSidebar"},"module-4/voice-to-action-whisper":{"id":"module-4/voice-to-action-whisper","title":"Voice-to-Action with OpenAI Whisper","description":"Implementing speech recognition and command interpretation using OpenAI Whisper","sidebar":"tutorialSidebar"}}}}